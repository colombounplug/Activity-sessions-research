This section is intended to both serve as a description of our methodology as well as to instruct readers on how to apply the same methods to their own dataset.  First, we'll discuss how we recommend applying our methodology for identifying inter-activity type component clusters to a dataset.  Next, we'll describe the origin of our datasets and the cleanup we performed in order to generate inter-activity times to fit.

\subsection{Fitting inter-activity times}
First, we must gather a dataset of user-initiated actions with timestamps of at least seconds resolution.  We generate inter-activity times on a per-user basis, so a relatively robust user identifier is necessary.  While a persistent user identifier such as one associated with a user account is preferable, we've found that, in the case of request logs, a fingerprint based on the request's IP and User-agent seems to be sufficient.

Once we have per-user inter-activity times, we plot a histogram based on the logarthmically scalled iter-activity time and look for evidence of a valley.  Given the observations we have seen (and report in section \ref{sec:results}), we expect to see a valley around about 1 hour with peaks around 1 minute and 1 day.  It's at this time that anomalies in the data should be detected and removed.  For example, we found that the time between Wikimedia Mobile Views (described in the next section) had an absurd spike at exactly 18 minutes of inter-activity time caused by a few (likely automated) users and removed their activities from the dataset.

Next, we try to fit a two component gaussian mixture model using expectation maximization\cite{benaglia2009mixtools} and visually inspect the results\footnote{Note that we tried several strategies for statistically confirming the most appropriate fit -- of which we found Davies--Bouldin index (DBI)\cite{davies1979cluster} to be most reasonable -- but none were as good as a simple visual inspection, so we employ and recommend the same.}  When the simple bimodal components did not appear to fit the data appropriately, we explored the addition of components to the mixture model with careful skepticism and repeated visual inspection.

Finally, if we have found what appears to be an appropriate fit, we identify a theoretically optimal inter-activity threshold for identifying sessions by finding the point where inter-activity time is equally likely to be within the gaussians fit with sub-hour means (within-session) and gaussians fit with means beyond an hour (between-session).

\subsection{Datasets}
\FIXME{Oliver writes up dataset descriptions}
